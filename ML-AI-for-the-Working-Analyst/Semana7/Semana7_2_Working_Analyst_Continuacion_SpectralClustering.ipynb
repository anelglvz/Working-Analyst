{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anelglvz/Working-Analyst/blob/main/ML-AI-for-the-Working-Analyst/Semana%207/Semana7_2_Working_Analyst_Continuacion_SpectralClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1JLny2jgpf1"
      },
      "source": [
        "# Clusterización de trayectorias usando Clustering Espectral y KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0W3OmtyJ4ne"
      },
      "source": [
        "## Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzb8dsqBrmJO"
      },
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "import os\n",
        "import scipy.io\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "from scipy import linalg\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Some visualization stuff, not so important\n",
        "sns.set()\n",
        "plt.rcParams['figure.figsize'] = (10, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tOn_Sjg6yQ24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsH08z2WgnZO"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRR7C0K0A6ju"
      },
      "source": [
        "def plot_cluster(traj_lst, cluster_lst):\n",
        "    cluster_count = np.max(cluster_lst) + 1\n",
        "    \n",
        "    for traj, cluster in zip(traj_lst, cluster_lst):\n",
        "        plt.plot(traj[:, 0], traj[:, 1], c=plt.cm.tab20(cluster))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGkYr8fThSbs"
      },
      "source": [
        "## Obtención de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyM6Z1kwh3tX"
      },
      "source": [
        "Trabajaremos con el dataset LABOMNI que contiene trayectorias de humanos caminando por un laboratorio capturadas usando una cámara omni-direccional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KL5mJY3BAon"
      },
      "source": [
        "# link descontinuado 'http://cvrr.ucsd.edu/LISA/Datasets/TrajectoryClustering/CVRR_dataset_trajectory_clustering.zip', era el oficial\n",
        "\n",
        "filename = '/content/drive/MyDrive/Curso-WorkingAnalyst/semana7/labomni.mat'\n",
        "\n",
        "###### Función util si aún hay link, descarga un .zip\n",
        "# is_download_required = not os.path.exists(data_folder)\n",
        "\n",
        "#if is_download_required:\n",
        "#    zip_filename = 'data.zip'\n",
        "#    urllib.request.urlretrieve(dataset_link, zip_filename)\n",
        "#    zip_ref = zipfile.ZipFile(zip_filename, 'r')\n",
        "#    zip_ref.extractall(data_folder)\n",
        "#    zip_ref.close()\n",
        "\n",
        "# Import dataset\n",
        "traj_data = scipy.io.loadmat(filename)['tracks']\n",
        "\n",
        "traj_lst = []\n",
        "for data_instance in traj_data:\n",
        "    traj_lst.append(np.vstack(data_instance[0]).T)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = scipy.io.loadmat(filename)"
      ],
      "metadata": {
        "id": "YdiKh1to6FuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data['tracks'][0][0].T"
      ],
      "metadata": {
        "id": "B9OF3Rtq6WRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La longitud de la lista es la cantidad de caminos\n",
        "traj_lst"
      ],
      "metadata": {
        "id": "CuE1U3gg8vvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traj_lst[0].shape"
      ],
      "metadata": {
        "id": "mDHss3n89N0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epIMvsz8CEe-"
      },
      "source": [
        "## Visualización de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNLMow09BESC"
      },
      "source": [
        "# Plotting\n",
        "\n",
        "for traj in traj_lst:\n",
        "    plt.plot(traj[:, 0], traj[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7p54Ti0B3Xn"
      },
      "source": [
        "plt.plot(traj_lst[157][:,0],traj_lst[157][:,1])\n",
        "plt.plot(traj_lst[193][:,0],traj_lst[193][:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploración de los datos\n",
        "\n"
      ],
      "metadata": {
        "id": "eWJlxCjmzzfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# auxiliar\n",
        "lenghts = [len(i) for i in traj_lst]\n",
        "\n",
        "array = np.array(lenghts)"
      ],
      "metadata": {
        "id": "-bCSA3r3z-zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pequeño ejercicio: \n",
        "# Encontrar los conjuntos de puntos mas grande y el mas pequeño \n",
        "#                        Pista: np.where()\n",
        "index = np.where(array == array.max())[0][0]   \n",
        "print(index)\n",
        "traj_lst[index]"
      ],
      "metadata": {
        "id": "6j2SyUeA0jiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.argmax(array)\n",
        "index"
      ],
      "metadata": {
        "id": "q-rTTeyF_a6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(traj_lst[index])"
      ],
      "metadata": {
        "id": "y3KIfTLuCXDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2 = np.where(array == array.min())[0][0]\n",
        "print(index2)\n",
        "len(traj_lst[index2])"
      ],
      "metadata": {
        "id": "7j3peJUwBZAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2 = np.argmin(array)\n",
        "index2"
      ],
      "metadata": {
        "id": "jN9uy6rI_cd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En realidad, ¿que son nuestros datos?\n",
        "plt.scatter(traj_lst[193][:,0], traj_lst[193][:,1])"
      ],
      "metadata": {
        "id": "R5rKZrZl1oPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distancia de Hausdorff"
      ],
      "metadata": {
        "id": "VLMMGJwk1wD5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoYAs8ynknuj"
      },
      "source": [
        "Para calcular la similitud entre dos trayectorias utilizaremos la distancia de Hausdorff programada en [```scipy.spatial.distance.directed_hausdorff```](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.directed_hausdorff.html). ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Resulta familiar?\n",
        "punto_a = np.array([[0,0]])\n",
        "punto_b = np.array([[3,4]])\n",
        "directed_hausdorff(punto_b, punto_a)"
      ],
      "metadata": {
        "id": "f4o1_88o14Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Y ahora?\n",
        "conj_a = np.array([[1,1],[0,0]])\n",
        "conj_b = np.array([[1,1]])\n",
        "directed_hausdorff(conj_a, conj_b)"
      ],
      "metadata": {
        "id": "BvjKYJqT_uzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Y ahora?\n",
        "conj_a = np.array([[1,1],[0,0]])\n",
        "conj_b = np.array([[1,1]])\n",
        "directed_hausdorff(conj_b, conj_a)"
      ],
      "metadata": {
        "id": "ft5FPs_p2g_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intente calcular la distancia de hausdorff entre 2 elementos y vea gráficamente que ocurre"
      ],
      "metadata": {
        "id": "2qm2mAqr3L9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO_2sk3NkYDF"
      },
      "source": [
        "## Matriz de similitud/distancia/adyacencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6GphLw3BahG"
      },
      "source": [
        "%%time\n",
        "def hausdorff( u, v):\n",
        "    d = max(directed_hausdorff(u, v)[0], directed_hausdorff(v, u)[0])\n",
        "    return d\n",
        "\n",
        "traj_count = len(traj_lst)\n",
        "A = np.zeros((traj_count, traj_count))\n",
        "\n",
        "# This may take a while\n",
        "for i in range(traj_count):\n",
        "    for j in range(traj_count):\n",
        "        distance = hausdorff(traj_lst[i], traj_lst[j])\n",
        "        A[i, j] = distance\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmA_RaLfBkL9"
      },
      "source": [
        "print(A.shape)\n",
        "A[:10, :4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PENDIENTE (minimo sin contar los ceros)\n",
        "np.min(A[A > 0])"
      ],
      "metadata": {
        "id": "q3ZUI_NqMjRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9MYbYEwmTpc"
      },
      "source": [
        "## Clustering Espectral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH7r-Vm9Nwvy"
      },
      "source": [
        "Obtenemos la $D$ que es una matriz diagonal en la que tendremos el ```grado``` de la trayectoría $i$ en la $i-ésima$ entrada.\n",
        "\n",
        "$D_{i} = \\sum_j A_{i, j}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_vect = np.sum(A,axis = 1) # Suma por renglones\n",
        "D_vect"
      ],
      "metadata": {
        "id": "u9VdbbifNzBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_rEmL6Brtz"
      },
      "source": [
        "D = np.diag(D_vect) # matriz diagonal de un vector\n",
        "D[:10, :4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Me6x6EYNkwG"
      },
      "source": [
        "Calculamos la matriz $L$. No es la matriz Laplaciana de $A$, pero esta relacionada.\n",
        "\n",
        "$L = D^{-1/2}~A~D^{-1/2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfo2MhfoLWsn"
      },
      "source": [
        "D_sqrtinv = np.diag(np.sqrt(1/D_vect))\n",
        "L_norm = D_sqrtinv @ A @ D_sqrtinv\n",
        "L_norm[:10, :4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_norm.shape"
      ],
      "metadata": {
        "id": "5G60YUcm4sWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmiwlHKnmRp-"
      },
      "source": [
        "Hacemos la descomposición en valores singulares \n",
        "\n",
        "$L = U~\\Sigma~V^T$.\n",
        "\n",
        "Los eigenvectores van son las columnas de $U$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJbKgu9gMBWu"
      },
      "source": [
        "U, sigma, _ = linalg.svd(L_norm, full_matrices=False)\n",
        "print(U.shape, sigma.shape)\n",
        "sigma[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(L_norm - U @ np.diag(sigma) @ U.T)"
      ],
      "metadata": {
        "id": "g96-dmcDA3gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suma = np.sum(sigma)\n",
        "suma_parcial = np.sum(sigma[:15])\n",
        "suma_parcial/suma"
      ],
      "metadata": {
        "id": "WsEloZ_lRJ5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma[200]"
      ],
      "metadata": {
        "id": "GAewVtzdRiXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rxBkKoNnO6k"
      },
      "source": [
        "Definimos $k$ como el número de clusters que queremos crear y nos *quedamos* con los $k$ eigenvectores correspondientes a los $k$ eigenvalores más grandes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXdLUyXDOQcC"
      },
      "source": [
        "j = 15\n",
        "Uj = U[:, :j]\n",
        "Uj.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_TaSFJ9newW"
      },
      "source": [
        "Finalmente, normalizamos cada fila de la matriz resultante, $U_k$, y ocupamos éstas como *feature vectors* para KMeans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmAuQ4VZn6y"
      },
      "source": [
        "k = 15\n",
        "y_pred = KMeans(n_clusters = k).fit_predict(normalize(Uj))\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred + 1"
      ],
      "metadata": {
        "id": "4lZ2fkG-RXyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "id": "GV-t6yKCDsli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HAneQtUfIaS"
      },
      "source": [
        "plot_cluster(traj_lst, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_n = 4\n",
        "plot_cluster([traj_lst[i] for i in np.where(y_pred == cluster_n)[0]], y_pred[y_pred == cluster_n])"
      ],
      "metadata": {
        "id": "j9TRB0_UAUeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcJQ7FtMBh9c"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "282P3BdrBmAm"
      },
      "source": [
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOsM7_IhjAXl"
      },
      "source": [
        "### Ejercicios\n",
        "\n",
        "- En este notebook esta implementado el algoritmo de Ng, Jordan y Weiss (NJW). Implementar cualquier otro algoritmo ([referencia](https://sites.stat.washington.edu/spectral/papers/UW-CSE-03-05-01.pdf))\n",
        "- Comparar los resultados obtenidos con los verdaderos clusters que se encuentran en ```scipy.io.loadmat(filename)['truth']``` (pistas abajo)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = scipy.io.loadmat(filename)['truth']"
      ],
      "metadata": {
        "id": "5uUYJbY9PlQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true.reshape(1,-1)"
      ],
      "metadata": {
        "id": "jOD1rrb5WK_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_pd = pd.DataFrame([element[0] for element in y_true])"
      ],
      "metadata": {
        "id": "IDcC9DtuQcG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_pd.value_counts()"
      ],
      "metadata": {
        "id": "wPD330QSFr_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "oX2h588pR1CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparative = pd.concat([true_pd, pd.DataFrame(y_pred, columns=[1])], axis=1)"
      ],
      "metadata": {
        "id": "Pmt4_vXfRLeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparative.rename(columns = {0:'True', 1:'Predicted'}, inplace = True)"
      ],
      "metadata": {
        "id": "8drT6akESQr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparative"
      ],
      "metadata": {
        "id": "sOWQxvA2SdgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparative[comparative['True'] == comparative['Predicted']]"
      ],
      "metadata": {
        "id": "afwm5hiWSHtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otro Ejercicio: ¿Porque creen que pasa lo anterior?"
      ],
      "metadata": {
        "id": "yKzJZ4LwS80n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cluster_n in range(1,k+1):\n",
        "  plot_cluster([traj_lst[i] for i in np.where(y_pred == cluster_n)[0]], y_pred[y_pred == cluster_n])"
      ],
      "metadata": {
        "id": "2n2t7am8NKXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_aux = y_true.reshape(209,).copy()\n",
        "y_aux"
      ],
      "metadata": {
        "id": "7KG7lEeYN1hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cluster_n in range(1,16):\n",
        "  plot_cluster([traj_lst[i] for i in np.where(y_pred == cluster_n)[0]], y_pred[y_aux == cluster_n])"
      ],
      "metadata": {
        "id": "DRfPm70RBnhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selección de número de clusters"
      ],
      "metadata": {
        "id": "EgB5lwhFJKzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método \"Elbow\""
      ],
      "metadata": {
        "id": "DYe4id6cJPR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yellowbrick"
      ],
      "metadata": {
        "id": "lYCVjcwLJbmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer"
      ],
      "metadata": {
        "id": "AfNYlaO9JaTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funciones \"KelbowVisualizer\" permite mas metricas aparte de la metrica \"distortion\" (distancias media de elementos a sus centroides). Permite la metrica \"silhouette\" que calcula la media del coeficiente Silhouette (medida de que tan bien está clasificado cada grupo), y \"calinski_harabasz\" que calcula el radio de dispersion entre clusters y dentro del cluster.\n"
      ],
      "metadata": {
        "id": "QjCVbcUkKia4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codo = KElbowVisualizer(KMeans(random_state=3), k=(4,20))\n",
        "codo.fit(normalize(Uj))\n",
        "codo.poof()"
      ],
      "metadata": {
        "id": "xZmgBRGaJSm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando otra de las métricas"
      ],
      "metadata": {
        "id": "9o1O3udfMkSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codo = KElbowVisualizer(KMeans(random_state=3), k=(4,20), metric='silhouette')\n",
        "codo.fit(normalize(Uj))\n",
        "codo.poof()"
      ],
      "metadata": {
        "id": "aBQsaBNKMmrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El coeficiente de Silhouette evalúa la cercania entre puntos de un mismo cluster al mismo tiempo que la distancia a los clusters vecinos.\n",
        "\n",
        "El coeficiente de Silhouette oscila entre -1 y 1 donde 1 indica un clúster de alta densidad y -1 que no existe densidad alguna."
      ],
      "metadata": {
        "id": "k0Aw-KBHLtnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(12)\n",
        "graf_sil = SilhouetteVisualizer(model)\n",
        "graf_sil.fit(normalize(Uj))\n",
        "graf_sil.poof()"
      ],
      "metadata": {
        "id": "N_XkbpWTLtYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Que pasaría si nos quedamos con mas características representativas"
      ],
      "metadata": {
        "id": "OZLGXyydOpbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "j = 13\n",
        "Uj = U[:, :j]\n",
        "Uj.shape"
      ],
      "metadata": {
        "id": "xUbWiZF1OtoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codo = KElbowVisualizer(KMeans(random_state=3), k=(4,20))\n",
        "codo.fit(normalize(Uj))\n",
        "codo.poof()"
      ],
      "metadata": {
        "id": "1epo-uIvO7pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codo = KElbowVisualizer(KMeans(), k=(4,20), metric='silhouette')\n",
        "codo.fit(normalize(Uj))\n",
        "codo.poof()"
      ],
      "metadata": {
        "id": "f__EV1gGO9KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(7)\n",
        "graf_sil = SilhouetteVisualizer(model)\n",
        "graf_sil.fit(normalize(Uj))\n",
        "graf_sil.poof()"
      ],
      "metadata": {
        "id": "drB9N17oPNG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
