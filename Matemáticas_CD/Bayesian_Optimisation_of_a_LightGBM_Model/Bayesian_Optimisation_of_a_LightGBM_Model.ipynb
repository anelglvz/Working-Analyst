{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9dJFWDzWLJM9ASpmOZQb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anelglvz/Working-Analyst/blob/main/Matem%C3%A1ticas_CD/Bayesian_Optimisation_of_a_LightGBM_Model/Bayesian_Optimisation_of_a_LightGBM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Optimisation of a LightGBM Model"
      ],
      "metadata": {
        "id": "DhtvgKG0WPbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Modeling\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "\n",
        "# Evaluation of the model\n",
        "#from sklearn.model_selection import KFold\n"
      ],
      "metadata": {
        "id": "REcQUY5mW7kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EVALS = 100\n",
        "N_FOLDS = 10"
      ],
      "metadata": {
        "id": "oSHtGgqZWIBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data"
      ],
      "metadata": {
        "id": "A8eXj5pSWM_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data details: https://www.kaggle.com/datasets/uciml/caravan-insurance-challenge"
      ],
      "metadata": {
        "id": "3FulqS39h4kw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcTwO-QwHQu8"
      },
      "outputs": [],
      "source": [
        "link = 'https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/data/caravan-insurance-challenge.csv?raw=true'\n",
        "data = pd.read_csv(link)\n",
        "print(data.shape)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data[data['ORIGIN'] == 'train']\n",
        "test = data[data['ORIGIN'] == 'test']\n",
        "\n",
        "train_labels = np.array(train['CARAVAN'].astype(np.int32)).reshape((-1,)) # Número de pólizas de casas móviles\n",
        "test_labels = np.array(test['CARAVAN'].astype(np.int32)).reshape((-1,)) # Número de pólizas de casas móviles\n",
        "\n",
        "# Drop the unneeded columns\n",
        "train = train.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
        "test = test.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
        "\n",
        "# Convert to numpy array for splitting in cross validation\n",
        "features = np.array(train)\n",
        "test_features = np.array(test)\n",
        "labels = train_labels[:]\n",
        "\n",
        "print('Train shape: ', train.shape)\n",
        "print('Test shape: ', test.shape)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "onqwN_ZmXpZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(labels, edgecolor = 'k'); \n",
        "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Counts of Labels');"
      ],
      "metadata": {
        "id": "3AZA_Ap6ZDAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Machine Default Model"
      ],
      "metadata": {
        "id": "2tCia-QDZQbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See details: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
      ],
      "metadata": {
        "id": "bbj_tLUWmxl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with default hyperparameters\n",
        "model = lgb.LGBMClassifier()\n",
        "model"
      ],
      "metadata": {
        "id": "JtnbWdmJZTkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timer()\n",
        "model.fit(features, labels)\n",
        "train_time = timer() - start\n",
        "\n",
        "predictions = model.predict_proba(test_features)[:, 1]\n",
        "auc = roc_auc_score(test_labels, predictions)\n",
        "\n",
        "print('The baseline score on the test set is {:.4f}.'.format(auc))\n",
        "print('The baseline training time is {:.4f} seconds'.format(train_time))"
      ],
      "metadata": {
        "id": "IMMZb0j0ZhSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El AUC varía en valor de 0 a 1. Un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0; uno cuyas predicciones son un 100% correctas tiene un AUC de 1.0."
      ],
      "metadata": {
        "id": "3QZVLFiGvbPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search\n"
      ],
      "metadata": {
        "id": "7maJ5nfQZwXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(lgb.LGBMClassifier())"
      ],
      "metadata": {
        "id": "KA0xdT_aZzxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'boosting_type': ['gbdt', 'goss'],\n",
        "    'num_leaves': list(range(30, 150)),\n",
        "    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n",
        "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
        "    'min_child_samples': list(range(20, 500, 5)),\n",
        "    'reg_alpha': list(np.linspace(0, 1)),\n",
        "    'reg_lambda': list(np.linspace(0, 1)),\n",
        "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
        "}\n",
        "\n",
        "# Subsampling (only applicable with 'goss'): This specifies the fraction of rows to consider at each subsampling stage. By default it is set to 1, which means no subsampling.\n",
        "subsample_dist = list(np.linspace(0.5, 1, 100))"
      ],
      "metadata": {
        "id": "jPIQjxPGaPds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM utiliza una técnica novedosa de muestreo de un lado basado en gradiente (GOSS) "
      ],
      "metadata": {
        "id": "72hiG8SBrHLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(param_grid['learning_rate'], color = 'r', edgecolor = 'k');\n",
        "plt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);"
      ],
      "metadata": {
        "id": "0ZLiSZ7naTjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(param_grid['num_leaves'], color = 'm', edgecolor = 'k')\n",
        "plt.xlabel('Learning Number of Leaves', size = 14); plt.ylabel('Count', size = 14); plt.title('Number of Leaves Distribution', size = 18);"
      ],
      "metadata": {
        "id": "IAhzH8eMacyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling from Hyperparameter Domain\n"
      ],
      "metadata": {
        "id": "vitL78oNaoRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
        "params"
      ],
      "metadata": {
        "id": "L6vNAtofajOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params['subsample'] = random.sample(subsample_dist, 1)[0] if params['boosting_type'] != 'goss' else 1.0\n",
        "params"
      ],
      "metadata": {
        "id": "BlhFTZt3a0Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation with Early Stopping in LightGBM\n"
      ],
      "metadata": {
        "id": "0QwZtLSna8Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See details: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.cv.html"
      ],
      "metadata": {
        "id": "UDL2NESFqhnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = lgb.Dataset(features, label = labels)"
      ],
      "metadata": {
        "id": "hwjkwOrNa98G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Perform cross validation with 10 folds\n",
        "r = lgb.cv(params, train_set, num_boost_round = 10000, nfold = 10, metrics = 'auc', \n",
        "           early_stopping_rounds = 100, verbose_eval = False, seed = 50)\n",
        "\n",
        "# Highest score\n",
        "r_best = np.max(r['auc-mean'])\n",
        "\n",
        "# Loss must be minimized\n",
        "loss = 1 - r_best\n",
        "\n",
        "# Standard deviation of best score\n",
        "r_best_std = r['auc-stdv'][np.argmax(r['auc-mean'])]\n",
        "\n",
        "print('The maximium ROC AUC on the validation set was {:.5f} with std of {:.5f}.'.format(r_best, r_best_std))\n",
        "print('The loss was {}.'.format(loss))\n",
        "print('The ideal number of iterations was {}.'.format(np.argmax(r['auc-mean']) + 1))"
      ],
      "metadata": {
        "id": "NnPcWMKybCtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_estimators = int(np.argmax(r['auc-mean']) + 1)    \n",
        "\n",
        "# Model with random hyperparameters\n",
        "best_random_model = lgb.LGBMClassifier(**params, n_estimators=random_estimators, n_jobs = -1, \n",
        "                                       objective = 'binary', random_state = 50)\n",
        "\n",
        "start = timer()\n",
        "model.fit(features, labels)\n",
        "train_time = timer() - start\n",
        "\n",
        "predictions = model.predict_proba(test_features)[:, 1]\n",
        "auc = roc_auc_score(test_labels, predictions)\n",
        "\n",
        "print('The baseline score on the test set is {:.4f}.'.format(auc))\n",
        "print('The baseline training time is {:.4f} seconds'.format(train_time))"
      ],
      "metadata": {
        "id": "eD2__K8FsSB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Dataframe"
      ],
      "metadata": {
        "id": "ZrkWJgCRWVpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe to hold cv results\n",
        "random_results = pd.DataFrame(columns = ['loss', 'params', 'iteration', 'estimators', 'time'],\n",
        "                       index = list(range(MAX_EVALS)))\n",
        "random_results"
      ],
      "metadata": {
        "id": "tYChXM5ObJaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective Function"
      ],
      "metadata": {
        "id": "rqLW0iW4Wb3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_objective(params, iteration, n_folds = N_FOLDS):\n",
        "    \"\"\"Random search objective function. Takes in hyperparameters\n",
        "       and returns a list of results to be saved.\"\"\"\n",
        "\n",
        "    start = timer()\n",
        "    \n",
        "    # Perform n_folds cross validation\n",
        "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
        "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
        "    end = timer()\n",
        "    best_score = np.max(cv_results['auc-mean'])\n",
        "    \n",
        "    # Loss must be minimized\n",
        "    loss = 1 - best_score\n",
        "    \n",
        "    # Boosting rounds that returned the highest cv score\n",
        "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
        "    \n",
        "    # Return list of results\n",
        "    return [loss, params, iteration, n_estimators, end - start]"
      ],
      "metadata": {
        "id": "d8tLyb9yWd0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search Implementation\n"
      ],
      "metadata": {
        "id": "m46wjIXPWnt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#%%time\n",
        "#random.seed(50)\n",
        "\n",
        "# Iterate through the specified number of evaluations\n",
        "for i in range(MAX_EVALS):\n",
        "    # Randomly sample parameters for gbm\n",
        "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
        "    \n",
        "    print(params)\n",
        "    \n",
        "    if params['boosting_type'] == 'goss':\n",
        "        # Cannot subsample with goss\n",
        "        params['subsample'] = 1.0\n",
        "    else:\n",
        "        # Subsample supported for gdbt and dart\n",
        "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
        "        \n",
        "        \n",
        "    results_list = random_objective(params, i)\n",
        "\n",
        "    # Add results to next row in dataframe\n",
        "    random_results.loc[i, :] = results_list"
      ],
      "metadata": {
        "id": "yt6V-9iXWpQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort results by best validation score\n",
        "random_results.sort_values('loss', ascending = True, inplace = True)\n",
        "random_results.reset_index(inplace = True, drop = True)\n",
        "random_results"
      ],
      "metadata": {
        "id": "JAERJezJW1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search Performance\n"
      ],
      "metadata": {
        "id": "vR3Tlg8eXq6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_results.loc[0, 'params']"
      ],
      "metadata": {
        "id": "ttSF_FlhXtdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best parameters and number of estimators\n",
        "best_random_params = random_results.loc[0, 'params'].copy()\n",
        "best_random_estimators = int(random_results.loc[0, 'estimators'])\n",
        "best_random_model = lgb.LGBMClassifier(n_estimators=best_random_estimators, n_jobs = -1, \n",
        "                                       objective = 'binary', **best_random_params, random_state = 50)\n",
        "\n",
        "# Fit on the training data\n",
        "best_random_model.fit(features, labels)\n",
        "\n",
        "# Make test predictions\n",
        "predictions = best_random_model.predict_proba(test_features)[:, 1]\n",
        "\n",
        "\n",
        "print('The best model from random search scores {:.4f} on the test data.'.format(roc_auc_score(test_labels, predictions)))\n",
        "print('This was achieved using {} search iterations.'.format(random_results.loc[0, 'iteration']))"
      ],
      "metadata": {
        "id": "e4lI1dmvX0XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Hyperparameter Optimization using Hyperopt"
      ],
      "metadata": {
        "id": "ZuGjEcPcX6d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective Function"
      ],
      "metadata": {
        "id": "ofFBLQOpYgQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe to hold cv results\n",
        "results = pd.DataFrame(columns = ['loss', 'params', 'iteration', 'estimators', 'train_time'],\n",
        "                       index = list(range(MAX_EVALS)))\n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "wHv84QlsKdac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import STATUS_OK\n",
        "\n",
        "def objective(params, n_folds = N_FOLDS):\n",
        "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
        "    \n",
        "    # Keep track of evals\n",
        "    global ITERATION\n",
        "    \n",
        "    ITERATION += 1\n",
        "    \n",
        "    # Retrieve the subsample if present otherwise set to 1.0\n",
        "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
        "    \n",
        "    # Extract the boosting type\n",
        "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
        "    params['subsample'] = subsample\n",
        "    \n",
        "    # Make sure parameters that need to be integers are integers\n",
        "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
        "        params[parameter_name] = int(params[parameter_name])\n",
        "    \n",
        "    start = timer()\n",
        "    \n",
        "    # Perform n_folds cross validation\n",
        "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
        "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
        "    \n",
        "    run_time = timer() - start\n",
        "    \n",
        "    # Extract the best score\n",
        "    best_score = np.max(cv_results['auc-mean'])\n",
        "\n",
        "    # Loss must be minimized\n",
        "    loss = 1 - best_score\n",
        "    \n",
        "    # Boosting rounds that returned the highest cv score\n",
        "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
        "\n",
        "    # Write to a DataFrame results\n",
        "    results.loc[ITERATION-1, :]=[loss, params, ITERATION, n_estimators, run_time]\n",
        "\n",
        "    # Dictionary with information for evaluation\n",
        "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
        "            'estimators': n_estimators, \n",
        "            'train_time': run_time, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "spJZ_NGPX8mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Domain Space"
      ],
      "metadata": {
        "id": "lbMkLgIsZ0Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import hp\n",
        "from hyperopt.pyll.stochastic import sample"
      ],
      "metadata": {
        "id": "cQSRMMPQZv8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the learning rate\n",
        "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}"
      ],
      "metadata": {
        "id": "vNcnHik8Z40a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_dist = []\n",
        "\n",
        "# Draw 10000 samples from the learning rate domain\n",
        "for _ in range(10000):\n",
        "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
        "    \n",
        "plt.figure(figsize = (8, 6))\n",
        "sns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\n",
        "plt.title('Learning Rate Distribution', size = 18); \n",
        "plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
      ],
      "metadata": {
        "id": "RAJB9-s9Z8p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discrete uniform distribution\n",
        "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
        "num_leaves_dist = []\n",
        "\n",
        "# Sample 10000 times from the number of leaves distribution\n",
        "for _ in range(10000):\n",
        "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
        "    \n",
        "# kdeplot\n",
        "plt.figure(figsize = (8, 6))\n",
        "sns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\n",
        "plt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);"
      ],
      "metadata": {
        "id": "JbDFyR0zb6jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional Domain"
      ],
      "metadata": {
        "id": "XHe8CsJWcAMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# boosting type domain \n",
        "boosting_type = {'boosting_type': hp.choice('boosting_type', \n",
        "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
        "                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n",
        "\n",
        "# Draw a sample\n",
        "params = sample(boosting_type)\n",
        "params"
      ],
      "metadata": {
        "id": "3R1CgvEeb9S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the subsample if present otherwise set to 1.0\n",
        "subsample = params['boosting_type'].get('subsample', 1.0)\n",
        "\n",
        "# Extract the boosting type\n",
        "params['boosting_type'] = params['boosting_type']['boosting_type']\n",
        "params['subsample'] = subsample\n",
        "\n",
        "params"
      ],
      "metadata": {
        "id": "N2I2o9LPcH4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Bayesian Domain"
      ],
      "metadata": {
        "id": "j-b-FvV-cOVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search space\n",
        "space = {\n",
        "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
        "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
        "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
        "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "z5xwKKEOcQJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of Sampling from the Domain"
      ],
      "metadata": {
        "id": "t1y-SkaHcUbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample from the full space\n",
        "x = sample(space)\n",
        "\n",
        "# Conditional logic to assign top-level keys\n",
        "subsample = x['boosting_type'].get('subsample', 1.0)\n",
        "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
        "x['subsample'] = subsample\n",
        "\n",
        "x"
      ],
      "metadata": {
        "id": "sXCD4LiwcbIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = sample(space)\n",
        "subsample = x['boosting_type'].get('subsample', 1.0)\n",
        "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
        "x['subsample'] = subsample\n",
        "x"
      ],
      "metadata": {
        "id": "a-UN4PDocfpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Algorithm"
      ],
      "metadata": {
        "id": "ee_iCX4Bcixd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import tpe\n",
        "\n",
        "# optimization algorithm\n",
        "tpe_algorithm = tpe.suggest"
      ],
      "metadata": {
        "id": "LYkp46d0cnWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results History"
      ],
      "metadata": {
        "id": "nuMtOGwkcth3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import Trials\n",
        "\n",
        "# Keep track of results\n",
        "bayes_trials = Trials()"
      ],
      "metadata": {
        "id": "ooc-FtfLcvFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization"
      ],
      "metadata": {
        "id": "LLDrb4DCc2DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin"
      ],
      "metadata": {
        "id": "RPfi6R61c6oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#%%capture\n",
        "\n",
        "# Global variable\n",
        "global  ITERATION\n",
        "\n",
        "ITERATION = 0\n",
        "\n",
        "# Run optimization\n",
        "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
        "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
      ],
      "metadata": {
        "id": "FarjZbq5c954"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the trials with lowest loss (highest AUC) first\n",
        "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
        "bayes_trials_results[:2]"
      ],
      "metadata": {
        "id": "OfM-84fidBeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort with best scores on top and reset index for slicing\n",
        "results.sort_values('loss', ascending = True, inplace = True)\n",
        "results.reset_index(inplace = True, drop = True)\n",
        "results.head()"
      ],
      "metadata": {
        "id": "AhAqyoEOdE_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.loc[0,'params']"
      ],
      "metadata": {
        "id": "Y8-xTou8YVXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Best Results"
      ],
      "metadata": {
        "id": "glAGMMWxdSJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the ideal number of estimators and hyperparameters\n",
        "best_bayes_estimators = int(results.loc[0, 'estimators'])\n",
        "best_bayes_params = results.loc[0, 'params'].copy()\n",
        "\n",
        "# Re-create the best model and train on the training data\n",
        "best_bayes_model = lgb.LGBMClassifier(n_estimators=best_bayes_estimators, n_jobs = -1, \n",
        "                                       objective = 'binary', random_state = 50, **best_bayes_params)\n",
        "best_bayes_model.fit(features, labels)"
      ],
      "metadata": {
        "id": "OdklzOLydNH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the testing data \n",
        "preds = best_bayes_model.predict_proba(test_features)[:, 1]\n",
        "print('The best model from Bayes optimization scores {:.5f} AUC ROC on the test set.'.format(roc_auc_score(test_labels, preds)))\n",
        "print('This was achieved after {} search iterations'.format(results.loc[0, 'iteration']))"
      ],
      "metadata": {
        "id": "FjNnPolDdWnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison to Random Search"
      ],
      "metadata": {
        "id": "F_08jJAcdnss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_random_params['method'] = 'random search'\n",
        "best_bayes_params['method'] = 'Bayesian optimization'\n",
        "best_params = pd.DataFrame(best_bayes_params, index = [0]).append(pd.DataFrame(best_random_params, index = [0]), \n",
        "                                                                  ignore_index = True, sort = True)\n",
        "best_params"
      ],
      "metadata": {
        "id": "5A6zp6rJdpZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe for storing parameters\n",
        "random_params = pd.DataFrame(columns = list(random_results.loc[0, 'params'].keys()),\n",
        "                            index = list(range(len(random_results))))\n",
        "\n",
        "# Add the results with each parameter a different column\n",
        "for i, params in enumerate(random_results['params']):\n",
        "    random_params.loc[i, :] = list(params.values())\n",
        "    \n",
        "random_params['loss'] = random_results['loss']\n",
        "random_params['iteration'] = random_results['iteration']\n",
        "random_params.head()"
      ],
      "metadata": {
        "id": "1nU_oQiZds-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe for storing parameters\n",
        "bayes_params = pd.DataFrame(columns = list(results.loc[0, 'params'].keys()),\n",
        "                            index = list(range(len(results))))\n",
        "\n",
        "# Add the results with each parameter a different column\n",
        "for i, params in enumerate(results['params']):\n",
        "    bayes_params.loc[i, :] = list(params.values())\n",
        "    \n",
        "bayes_params['loss'] = results['loss']\n",
        "bayes_params['iteration'] = results['iteration']\n",
        "\n",
        "bayes_params.head()"
      ],
      "metadata": {
        "id": "t9JJHyMwdydd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rates"
      ],
      "metadata": {
        "id": "i8tgUwU1d8KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20, 8))\n",
        "plt.rcParams['font.size'] = 18\n",
        "\n",
        "# Density plots of the learning rate distributions \n",
        "sns.kdeplot(learning_rate_dist, label = 'Sampling Distribution', linewidth = 2)\n",
        "sns.kdeplot(random_params['learning_rate'], label = 'Random Search', linewidth = 2)\n",
        "sns.kdeplot(bayes_params['learning_rate'], label = 'Bayes Optimization', linewidth = 2)\n",
        "plt.legend()\n",
        "plt.xlabel('Learning Rate'); plt.ylabel('Density'); plt.title('Learning Rate Distribution');"
      ],
      "metadata": {
        "id": "U9pr4JGid-iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class weight"
      ],
      "metadata": {
        "id": "idx6_SQHAQEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, sharey = True, sharex = True)\n",
        "\n",
        "# Bar plots of boosting type\n",
        "random_params['class_weight'].value_counts().plot.bar(ax = axs[0], figsize = (14, 6), color = 'orange', title = 'Random Search Boosting Type')\n",
        "bayes_params['class_weight'].value_counts().plot.bar(ax = axs[1], figsize = (14, 6), color = 'green', title = 'Bayes Optimization Boosting Type');"
      ],
      "metadata": {
        "id": "nqONRvziAIq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting Type"
      ],
      "metadata": {
        "id": "vMWmOaf_eEtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, sharey = True, sharex = True)\n",
        "\n",
        "# Bar plots of boosting type\n",
        "random_params['boosting_type'].value_counts().plot.bar(ax = axs[0], figsize = (14, 6), color = 'orange', title = 'Random Search Boosting Type')\n",
        "bayes_params['boosting_type'].value_counts().plot.bar(ax = axs[1], figsize = (14, 6), color = 'green', title = 'Bayes Optimization Boosting Type');"
      ],
      "metadata": {
        "id": "AwbOa4DreF4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of All Numeric Hyperparameters"
      ],
      "metadata": {
        "id": "9cH4SpCyeKey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each hyperparameter\n",
        "for i, hyper in enumerate(random_params.columns):\n",
        "    if hyper not in ['class_weight', 'boosting_type', 'iteration', 'subsample', 'metric', 'verbose']:\n",
        "        plt.figure(figsize = (14, 6))\n",
        "        # Plot the random search distribution and the bayes search distribution\n",
        "        if hyper != 'loss':\n",
        "            sns.kdeplot([sample(space[hyper]) for _ in range(1000)], label = 'Sampling Distribution')\n",
        "        sns.kdeplot(random_params[hyper], label = 'Random Search')\n",
        "        sns.kdeplot(bayes_params[hyper], label = 'Bayes Optimization')\n",
        "        plt.legend(loc = 1)\n",
        "        plt.title('{} Distribution'.format(hyper))\n",
        "        plt.xlabel('{}'.format(hyper)); plt.ylabel('Density');\n",
        "        plt.show();"
      ],
      "metadata": {
        "id": "nvAFzetgeRXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Losses"
      ],
      "metadata": {
        "id": "U4Y3vwY2g8AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe of just scores\n",
        "scores = pd.DataFrame({'ROC AUC': 1 - random_params['loss'], 'iteration': random_params['iteration'], 'search': 'random'})\n",
        "scores = scores.append(pd.DataFrame({'ROC AUC': 1 - bayes_params['loss'], 'iteration': bayes_params['iteration'], 'search': 'Bayes'}))\n",
        "\n",
        "scores['ROC AUC'] = scores['ROC AUC'].astype(np.float32)\n",
        "scores['iteration'] = scores['iteration'].astype(np.int32)\n",
        "\n",
        "scores.head()"
      ],
      "metadata": {
        "id": "BT6MJgWwg9Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18, 6))\n",
        "\n",
        "# Random search scores\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(1 - random_results['loss'].astype(np.float64), label = 'Random Search', edgecolor = 'k');\n",
        "plt.xlabel(\"Validation ROC AUC\"); plt.ylabel(\"Count\"); plt.title(\"Random Search Validation Scores\")\n",
        "plt.xlim(0.75, 0.78)\n",
        "\n",
        "# Bayes optimization scores\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(1 - bayes_params['loss'], label = 'Bayes Optimization', edgecolor = 'k');\n",
        "plt.xlabel(\"Validation ROC AUC\"); plt.ylabel(\"Count\"); plt.title(\"Bayes Optimization Validation Scores\");\n",
        "plt.xlim(0.75, 0.78);"
      ],
      "metadata": {
        "id": "5a-L2zOLhAbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot of scores over the course of searching\n",
        "sns.lmplot('iteration', 'ROC AUC', hue = 'search', data = scores, size = 8);\n",
        "plt.xlabel('Iteration'); plt.ylabel('ROC AUC'); plt.title(\"ROC AUC versus Iteration\");"
      ],
      "metadata": {
        "id": "JuvONtI0kwZm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}